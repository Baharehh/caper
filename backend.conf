include required(classpath("application"))

backend {
  default = "local"
  providers {

    google {
      actor-factory = "cromwell.backend.impl.jes.JesBackendLifecycleActorFactory"
      config {
        project = "YOUR_GC_PROJECT"
        root = "gs://YOUR_GCS_BUCKET"

        concurrent-job-limit = 1000
        genomics-api-queries-per-100-seconds = 1000
        maximum-polling-interval = 600

        genomics {
          auth = "application-default"
          compute-service-account = "default"
          endpoint-url = "https://genomics.googleapis.com/"
          restrict-metadata-access = false
        }

        filesystems {
          gcs {
            auth = "application-default"
          }
        }
      }
    }

    aws {
      actor-factory = "cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory"
      config {
        numSubmitAttempts = 6
        numCreateDefinitionAttempts = 6
        root = "s3://YOUR_S3_BUCKET"
        auth = "default"
        default-runtime-attributes {
          queueArn: "YOUR_AWS_BATCH_ARN"
        }
        filesystems {
          s3 {
            auth = "default"
          }
        }
      }
    }

    local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        run-in-background = true
        script-epilogue = "sleep 10 && sync"
        runtime-attributes = """
          Int? gpu
          String? docker
          String? docker_user
          String? singularity
        """
        submit = """
          ${if defined(singularity) then "" else "/bin/bash ${script} #"} if [ -z $SINGULARITY_BINDPATH ]; then SINGULARITY_BINDPATH=/; fi; singularity exec --cleanenv --home ${cwd} ${if defined(gpu) then '--nv' else ''} ${singularity} /bin/bash ${script}
        """
      }
    }

    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 10 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
          String? docker
          String? docker_user
          Int cpu = 1
          Int? gpu
          Int? time
          Int? memory_mb
          String? slurm_partition
          String? slurm_account
          String? slurm_extra_param
          String singularity
        """
        submit = """
          sbatch \
          --export=ALL \
          -J ${job_name} \
          -D ${cwd} \
          -o ${out} \
          -e ${err} \
          ${"-t " + time*60} \
          -n 1 \
          --ntasks-per-node=1 \
          ${true="--cpus-per-task=" false="" defined(cpu)}${cpu} \
          ${true="--mem=" false="" defined(memory_mb)}${memory_mb} \
          ${"-p " + slurm_partition} \
          ${"--account " + slurm_account} \
          ${true="--gres gpu:" false="" defined(gpu)}${gpu} \
          ${slurm_extra_param} \
          --wrap "${if defined(singularity) then '' else '/bin/bash ${script} #'} if [ -z $SINGULARITY_BINDPATH ]; then SINGULARITY_BINDPATH=/; fi; singularity exec --cleanenv --home ${cwd} ${if defined(gpu) then '--nv' else ''} ${singularity} /bin/bash ${script}"
        """
        kill = "scancel ${job_id}"
        exit-code-timeout-seconds = 180
        check-alive = "CHK_ALIVE=$(squeue --noheader -j ${job_id}); if [ -z $CHK_ALIVE ]; then /bin/bash -c 'exit 1'; else echo $CHK_ALIVE; fi"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }

    sge {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 10 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
          String? docker
          String? docker_user
          String sge_pe = "shm"
          Int cpu = 1
          Int? gpu
          Int? time
          Int? memory_mb
          String? sge_queue
          String? sge_extra_param
          String singularity
        """
        submit = """
          echo "${if defined(singularity) then '' else '/bin/bash ${script} #'} if [ -z $SINGULARITY_BINDPATH ]; then SINGULARITY_BINDPATH=/; fi; singularity exec --cleanenv --home ${cwd} ${if defined(gpu) then '--nv' else ''} ${singularity} /bin/bash ${script}" | qsub \
          -S /bin/sh \
          -terse \
          -b n \
          -N ${job_name} \
          -wd ${cwd} \
          -o ${out} \
          -e ${err} \
          ${if cpu>1 then "-pe " + sge_pe + " " else ""}${if cpu>1 then cpu else ""} \
          ${true="-l h_vmem=$(expr " false="" defined(memory_mb)}${memory_mb}${true=" / " false="" defined(memory_mb)}${if defined(memory_mb) then cpu else ""}${true=")m" false="" defined(memory_mb)} \
          ${true="-l s_vmem=$(expr " false="" defined(memory_mb)}${memory_mb}${true=" / " false="" defined(memory_mb)}${if defined(memory_mb) then cpu else ""}${true=")m" false="" defined(memory_mb)} \
          ${true="-l h_rt=" false="" defined(time)}${time}${true=":00:00" false="" defined(time)}\
          ${true="-l s_rt=" false="" defined(time)}${time}${true=":00:00" false="" defined(time)}\
          ${"-q " + sge_queue} \
          ${"-l gpu=" + gpu} \
          ${sge_extra_param} \
          -V
        """
        # cromwell is desinged to monitor rc (return code) file, which is generated/controlled
        # in ${script}, so if singularity does not run it due to some problems in singuarlity's
        # internal settings then rc file is not generated.
        # this can result in hanging of a cromwell process.
        # setting the below parameter enables monitoring by "check-alive".
        # it will take about "exit-code-timeout-seconds" x 3 time to detect failure.
        exit-code-timeout-seconds = 180

        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }

    pbs {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        script-epilogue = "sleep 30 && sync"
        concurrent-job-limit = 50
        runtime-attributes = """
          String? docker
          String? docker_user
          Int cpu = 1
          Int? gpu
          Int? time
          Int? memory_mb
          String? pbs_queue
          String? pbs_extra_param
          String singularity
        """
        submit = """
          echo "${if defined(singularity) then '' else '/bin/bash ${script} #'} if [ -z $SINGULARITY_BINDPATH ]; then SINGULARITY_BINDPATH=/; fi; singularity exec --cleanenv --home ${cwd} ${if defined(gpu) then '--nv' else ''} ${singularity} /bin/bash ${script}" | qsub \
          -N ${job_name} \
          -o ${out} \
          -e ${err} \
          ${true="-lselect=1:ncpus=" false="" defined(cpu)}${cpu}${true=":mem=" false="" defined(memory_mb)}${memory_mb}${true="mb" false="" defined(memory_mb)} \
          ${true="-lwalltime=" false="" defined(time)}${time}${true=":0:0" false="" defined(time)} \
          ${true="-lngpus=" false="" gpu>1}${if gpu>1 then gpu else ""} \
          ${"-q " + pbs_queue} \
          ${pbs_extra_param} \
          -V
        """
        exit-code-timeout-seconds = 180

        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }
  }
}

services {
  LoadController {
    class = "cromwell.services.loadcontroller.impl.LoadControllerServiceActor"
    config {      
      control-frequency = 21474834 seconds
    }
  }
}

system {
  abort-jobs-on-terminate = true
  graceful-server-shutdown = true
}

call-caching {
  enabled = false
  invalidate-bad-cache-results = true
}

google {
  application-name = "cromwell"
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    }
  ]
}

aws {
  application-name = "cromwell"
  auths = [
    {
      name = "default"
      scheme = "default"
    }
  ]
  region = "YOUR_AWS_REGION"
}

engine {
  filesystems {
    s3 {
      auth = "default"
    }
  }
}
