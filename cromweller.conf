[defaults]

## workflow settings
deep_copy=True

## MySQL settings
#mysql_db_ip=
#mysql_db_port=
#mysql_db_user=
#mysql_db_password=

## Cromwell server/client settings
server_ip=localhost
server_port=8000
#server_user=
#server_password=

## default backend
backend=local

## Other Cromwell settings
#use_call_caching=
#num_concurrent_tasks=
#num_concurrent_workflows=

#cromwell=

# local
out_dir=/srv/scratch/leepc12/cromweller_out_dir
tmp_dir=/srv/scratch/leepc12/cromweller_tmp_dir

# GC
gc_project=encode-1016
out_gcs_bucket=gs://encode-pipeline-test-runs/cromweller/out
tmp_gcs_bucket=gs://encode-pipeline-test-runs/cromweller/tmp

# AWS
#aws_batch_arn=ARN_TEST
#aws_region=us-west-1
out_s3_bucket=s3://encode-pipeline-test-runs/cromweller/out
tmp_s3_bucket=s3://encode-pipeline-test-runs/cromweller/tmp
use_gsutil_over_aws_s3=True

# to download data with URLs (http://, https://)
#http_user=
#http_password=

# SLURM
slurm_partition=akundaje
#slurm_account=akundaje
#slurm_extra_param=

# SGE
sge_queue=q
sge_pe=shm
sge_extra_param=

# PBS
#pbs_queue=
#pbs_extra_param=
